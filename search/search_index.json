{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Building Education Intelligent Agents With LangChain","text":"<p>This microsite supports a course on building intelligent agents using the Python LangChain libraries to support education.</p> <p>We believe that LLM-powered agents are an excellent foundation for  building general problem-solving agents and will be at the core of most educational  learning management systems in a few years.  Central to this philosophy is to empower agents to do planning, access relevant knowledge,  work with other agents, and cost-effectively use resources such as API and data queries.</p> <p>We use LangChain to build intelligent agents that can:</p> <ol> <li>Generate lesson plans customized to the needs of a specific student</li> <li>Generate micro-simulations that provide interactive animations</li> <li>Generate supporting classroom materials such as concept glossaries and quizzes that are contextualized to each students learning objectives</li> </ol> <p>We use examples that support teachers in K-12 education generating customizable simulations and lesson plans customized to each student.</p> <p>We are fully aware that LangChain is not a perfect solution. It is a dynamically evolving framework with almost daily releases that break our code.  Despite this challenge, it is the best that we have today.</p> <p>Please read the About Page for details on the course prerequisites and goals.  If you are using these materials in your own classes, be sure to read the Creative Commons License page.</p> <p>Dan McCreary on LinkedIn</p>"},{"location":"about/","title":"About This Course","text":""},{"location":"about/#prerequisites","title":"Prerequisites","text":"<p>Basic Computer Skills: Students should be comfortable with basic computer operations, including installing software, navigating file systems, and general internet usage.</p> <p>Familiarity with ChatGPT and AI Concepts: A basic understanding of artificial intelligence, machine learning, and specifically ChatGPT. This could include how AI models are trained and the general capabilities and limitations of language models.</p> <p>Programming Knowledge: Since LangChain involves working with APIs and possibly coding for integration, a foundational knowledge of programming (preferably in Python) is essential. This should include understanding of basic programming concepts like variables, loops, functions, and data structures.</p> <p>GitHub Experience: Basic familiarity with Git and GitHub, including cloning repositories, committing changes, and understanding version control concepts.</p>"},{"location":"about/#adaptive-learning","title":"Adaptive Learning","text":"<p>Our goal is to provide content for multiple learning pathways.  Students who are new to generative AI can focus on less technical topics such as prompt engineering.</p> <p>Students with a strong mastery of Python and machine learning can focus on topics such as building knowledge graphs to support intelligent agents that facilitate adaptive learning.</p>"},{"location":"about/#related-courses-and-microsites","title":"Related Courses and MicroSites","text":"<ul> <li>Prompt Engineering</li> <li>Generative AI for Teachers</li> <li>MicroSims</li> </ul>"},{"location":"advanced-topics/","title":"Advanced Topics","text":""},{"location":"advanced-topics/#knowledge-graphs","title":"Knowledge Graphs","text":"<p>How would you approach building a global education application that  integrates knowledge from thousands of sources including scraping the web and social media for content?</p> <p>How would you model this data in the form of a labeled property graph?</p> <p>Include: 1. Lesson Plan 2. Courses 3. Subjects 4. MicroSimulations 5. Educational Concepts 6. Concept Dependencies 7. Schools 8. Colleges 9. Universities 10. Degrees 11. Instructors</p> <p>How would you deal with the high variability of this data?</p> <p>How would you create embeddings on the vertices of the graph?</p>"},{"location":"contacts/","title":"Contact","text":""},{"location":"contacts/#primary-contact","title":"Primary Contact","text":"<p>Dan McCreary on LinkedIn</p>"},{"location":"contacts/#collaborators","title":"Collaborators","text":"<p>Sharat Batra batra052@umn.edu</p>"},{"location":"glossary/","title":"Glossary of Terms for Intelligent Agents with Python LangChain","text":""},{"location":"glossary/#prompt","title":"Prompt","text":"<pre><code>Generate a Glossary of Terms for a class on Python LangChain.\nReturn a single raw markdown file.\nEach term name should be in level 4 header \"####\"\nInclude terms around Python, Jupyter Notebooks, Agents, LLMs, Environment Variables, OpenAI, APIs, Vector Stores, Pinecone, RAG, Prompt Enrichment.\nList the terms in alphabetical order.\n</code></pre>"},{"location":"glossary/#contents","title":"Contents","text":"<ul> <li>Agents</li> <li>APIs (Application Programming Interfaces)</li> <li>Conda</li> <li>Embeddings</li> <li>Environment Variables</li> <li>Python</li> <li>Jupyter Notebooks</li> <li>LLMs (Large Language Models)</li> <li>OpenAI</li> <li>Pinecone</li> <li>RAG (Retrieval-Augmented Generation)</li> <li>Prompt Enrichment</li> <li>Semantic Search</li> <li>Vector Stores</li> <li>Similarity</li> </ul>"},{"location":"glossary/#adaptive-learning","title":"Adaptive Learning","text":"<p>Adaptive Learning is an educational method that uses computer algorithms to coordinate and adjust the learning content and experience to the individual needs and performance of each learner. In adaptive learning systems, the material adapts in real-time, providing personalized learning paths and activities based on the learner's strengths, weaknesses, and pace of learning.</p>"},{"location":"glossary/#agents","title":"Agents","text":"<p>In the context of LangChain and AI, agents refer to entities (usually software) that can perform actions or tasks autonomously or semi-autonomously, often based on some form of AI or machine learning algorithm.</p>"},{"location":"glossary/#apis-application-programming-interfaces","title":"APIs (Application Programming Interfaces)","text":"<p>APIs are a set of protocols and tools for building software and applications. They define how different software components should interact and are used to enable integration between different systems and services.</p>"},{"location":"glossary/#conda","title":"Conda","text":"<p>Conda is an open-source package management and environment management system. It is used to install, run, and update packages and their dependencies. Conda is popular in the data science and machine learning communities, as it simplifies the process of setting up different environments for different projects with varying dependencies.</p>"},{"location":"glossary/#context-window","title":"Context Window","text":"<p>The Context Window in natural language processing refers to the amount of text (in terms of words or tokens) that a language model can consider at one time when generating a response or prediction. This window defines the scope of the model's immediate understanding. In large language models like GPT-3, the context window determines how much prior text is used to inform the model's current output.</p>"},{"location":"glossary/#deep-neural-network","title":"Deep Neural Network","text":"<p>A Deep Neural Network (DNN) is an advanced type of neural network that contains multiple hidden layers between the input and output layers. Each layer of neurons refines the information processed by the previous layer, allowing the network to learn and make sense of complex data with high levels of abstraction and accuracy. DNNs are the foundation of deep learning and are particularly powerful in handling large and complex datasets.</p>"},{"location":"glossary/#embeddings","title":"Embeddings","text":"<p>Embeddings are a form of representation that converts high-dimensional data, like text or images, into a lower-dimensional vector space. In the context of language models, word or sentence embeddings represent the meanings of words or sentences as vectors. These vectors capture semantic relationships and are used in various machine-learning tasks, including semantic search and natural language processing.</p>"},{"location":"glossary/#environment-variables","title":"Environment Variables","text":"<p>Environment variables are dynamic-named values that can affect the way running processes will behave on a computer. They are often used to manage configurations and settings for software applications and operating systems.</p> <p>In this course, all environment variables are stored in a <code>.env</code> file and should never be checked into your GitHub repository.</p>"},{"location":"glossary/#family-educational-rights-and-privacy-act","title":"Family Educational Rights and Privacy Act","text":"<p>The Family Educational Rights and Privacy Act (FERPA) is a federal law that affords parents the right to have access to their children\u2019s education records, the right to seek to have the records amended, and the right to have some control over the disclosure of personally identifiable information from the education records. When a student turns 18 years old, or enters a postsecondary institution at any age, the rights under FERPA transfer from the parents to the student (\u201celigible student\u201d). The FERPA statute is found at 20 U.S.C. \u00a7 1232g and the FERPA regulations are found at 34 CFR Part 99.</p>"},{"location":"glossary/#foundation-model","title":"Foundation Model","text":"<p>A Foundation Model refers to a type of large-scale machine learning model that is trained on a broad dataset and is adaptable to a wide range of tasks and domains without task-specific training data. These models, like GPT (Generative Pre-trained Transformer) from OpenAI, are foundational in the sense that they can be fine-tuned or adapted for various specific applications, forming the base for numerous downstream tasks.</p>"},{"location":"glossary/#generative-ai","title":"Generative AI","text":"<p>Generative AI refers to artificial intelligence models that can generate new content, including text, images, music, and more. These models learn patterns in the input data and use this understanding to create new, original outputs that are similar in nature to the training data. Examples include text generation models like GPT-3, image generation models, and music composition AI.</p> <ul> <li>US Government Student Privacy FAQ on FIRPA</li> </ul>"},{"location":"glossary/#gpu-graphics-processing-unit","title":"GPU (Graphics Processing Unit)","text":"<p>A GPU, or Graphics Processing Unit, is a specialized processor designed to accelerate graphics rendering. GPUs are also widely used in the field of deep learning and AI, as they can process multiple parallel tasks efficiently, making them ideal for training complex neural networks and handling large-scale data processing.</p>"},{"location":"glossary/#graph-embeddings","title":"Graph Embeddings","text":"<p>Graph Embeddings are data structures used to find similar items in a graph.  To create them we look at nodes, edges, and their features into a vector space while preserving the graph structure. This representation allows for the application of machine learning techniques to graph data, facilitating tasks like node classification, link prediction, and graph visualization. Graph embeddings are essential in processing network-structured data efficiently.</p>"},{"location":"glossary/#graph-machine-learning","title":"Graph Machine Learning","text":"<p>Graph Machine Learning refers to a set of techniques and models that operate on data represented as graphs. It combines elements of graph theory with machine learning to process and analyze data that contains complex relationships and interdependencies. This approach is useful in various applications such as social network analysis, recommendation systems, and fraud detection, where data points are interrelated in non-trivial ways.</p>"},{"location":"glossary/#jupyter-notebook","title":"Jupyter Notebook","text":"<p>A Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. They are commonly used for data cleaning and transformation, numerical simulation, statistical modeling, data visualization, and machine learning.</p> <p>Our course will require the use of Jupyter Notebooks in assignments.</p>"},{"location":"glossary/#knowledge-graph","title":"Knowledge Graph","text":"<p>A Knowledge Graph is a network of entities and their interrelations, organized in a graph format. It is used to store interconnected descriptions of entities \u2014 objects, events, situations, or concepts. Knowledge graphs are integral in various AI applications for providing structured and accessible data that machines can use to perform semantic searches, make recommendations, and understand complex queries.</p>"},{"location":"glossary/#knowledge-spaces","title":"Knowledge Spaces","text":"<p>Knowledge Spaces refer to a theoretical framework in the field of educational psychology and learning sciences. They represent the range of knowledge and skills in a particular domain, structured in a way that reflects how learning typically progresses. In this framework, knowledge is organized as a network of interconnected concepts, allowing educators to identify and target specific areas where a learner needs development.</p>"},{"location":"glossary/#large-language-model-llm","title":"Large Language Model (LLM)","text":"<p>A Large Language Model (LLM) is a type of machine learning model designed to understand, interpret, and generate human language. These models are 'large' both in terms of the size of the training data they are exposed to and their own architectural complexity. LLMs are trained on vast datasets of text and are capable of performing a wide range of natural language processing tasks.</p>"},{"location":"glossary/#lesson-plan","title":"Lesson Plan","text":"<p>A Lesson Plan is a teacher's detailed description of the course of instruction for a class. A well-crafted lesson plan outlines the objectives, teaching and learning activities, and resources needed to carry out a particular lesson. It serves as a guide for teachers to manage the learning environment and ensure consistent coverage of curriculum and fulfillment of learning objectives.</p>"},{"location":"glossary/#llms-large-language-models","title":"LLMs (Large Language Models)","text":"<p>LLMs, or Large Language Models, are advanced AI models trained on vast datasets to understand, interpret, and generate human language. Examples include OpenAI's GPT (Generative Pre-trained Transformer) series.</p>"},{"location":"glossary/#llmp","title":"LLM+P","text":"<ul> <li>LLM+P: Empowering Large Language Models with Optimal Planning Proficiency</li> </ul>"},{"location":"glossary/#neural-network","title":"Neural Network","text":"<p>A Neural Network is a computational model inspired by the structure of the human brain. It consists of interconnected nodes, or 'neurons,' organized in layers. Each connection can transmit a signal from one neuron to another. The receiving neuron processes the signal and signals downstream neurons connected to it. Neural networks are used in machine learning for pattern recognition and data classification, among other tasks.</p>"},{"location":"glossary/#openai","title":"OpenAI","text":"<p>OpenAI is an AI research lab consisting of the for-profit corporation OpenAI LP and its parent company, the non-profit OpenAI Inc. OpenAI is known for its work in the field of artificial intelligence, including the development of the GPT series of language models.</p>"},{"location":"glossary/#planning-domain-definition-language-pddl","title":"Planning Domain Definition Language (PDDL)","text":"<p>A formal language used in business and technology sectors to define and model complex planning and scheduling tasks. PDDL allows organizations to articulate the structure of a planning domain, the initial conditions, and the desired goals. </p> <p>PDDL is primarily used in AI-driven systems to automate decision-making processes, optimize resource allocation, and manage complex logistical operations. By employing PDDL, businesses can efficiently model various scenarios, simulate outcomes, and develop strategic plans that are robust, flexible, and adaptable to changing conditions. This language is instrumental in industries like manufacturing, supply chain management, robotics, and any field where automated planning is essential.</p>"},{"location":"glossary/#pinecone","title":"Pinecone","text":"<p>Pinecone is a scalable vector database service that enables efficient vector search and storage. It's used for managing high-dimensional vector embeddings in machine learning applications, particularly in natural language processing.</p>"},{"location":"glossary/#processing-and-p5js","title":"Processing and P5.js","text":"<p>Processing is a flexible software sketchbook and a language for learning how to code within the context of the visual arts. P5.js is a JavaScript library that has the same goals, focusing on making coding accessible for artists, designers, educators, and beginners. Both Processing and P5.js are used to create graphics and interactive experiences.</p>"},{"location":"glossary/#prompt-engineering","title":"Prompt Engineering","text":"<p>Prompt Engineering is the process of designing and refining the input (or 'prompt') given to a language model to elicit the most accurate or relevant output. It involves creatively framing the prompt and including specific instructions or context that guide the model's response. Effective prompt engineering is crucial for maximizing the performance of language models, especially in applications like chatbots, content creation, and problem-solving.</p>"},{"location":"glossary/#prompt-enrichment","title":"Prompt Enrichment","text":"<p>Prompt enrichment involves adding additional context or information to the prompts given to language models, to guide or improve their responses. This can include context from previous interactions, relevant external information, or specific instructions on how the model should respond.</p>"},{"location":"glossary/#python","title":"Python","text":"<p>Python is a high-level, interpreted programming language known for its simplicity and readability.  It's widely used for various applications, from web development to data science and machine learning. Because of the extensive use of Python in open-source projects, there is ample training data for generative AI tools to use.  As a result, the quality of code generated by many generative AI tools is much higher than in other programming languages.</p> <p>All of our code uses Python version 3.</p>"},{"location":"glossary/#responsive-design","title":"Responsive Design","text":"<p>Techniques ensuring simulations and other user interfaces work well on various devices and screen sizes.  Our goal is to allow all our user interfaces to also run on devices such as mobile phones, tablets and large-screen monitors.</p>"},{"location":"glossary/#retrieval-augmented-generation-rag","title":"Retrieval-Augmented Generation (RAG)","text":"<p>Retrieval-Augmented Generation (RAG), is a method combining a retrieval system with a generative language model.  It enhances the language model's responses by retrieving relevant information from a database or document collection.</p> <p>Note</p> <p>Use this term carefully.  The original paper on RAG only used public knowledge from Wikipedia to enrich the prompt.  Use the term Prompt Enrichment for a more general pattern.</p> <ul> <li>See also Prompt Enrichment</li> <li>Link to RAG paper on the arxive.org site: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</li> </ul>"},{"location":"glossary/#semantic-search","title":"Semantic Search","text":"<p>Semantic Search refers to a search technique that aims to understand the searcher's intent and the contextual meaning of terms as they appear in the searchable dataspace. It contrasts with keyword search, which looks for exact matches of the query words without understanding the context or meaning behind them. Semantic search, often powered by AI and natural language understanding, provides more relevant search results by understanding the intent and contextual meaning of the search query.</p>"},{"location":"glossary/#similarity","title":"Similarity","text":"<p>In the context of machine learning and LangChain, similarity refers to the measure of how closely related two items are in their representations, often used with embeddings. This concept is crucial in tasks like semantic search, where the goal is to find items (e.g., documents, images) that are similar or relevant to a query, based on their vector representations in the embedding space.</p>"},{"location":"glossary/#smart-board","title":"Smart Board","text":"<p>An interactive whiteboard, also known as an interactive board or smart board, is a large interactive display board in the form factor of a whiteboard. In many classrooms, an instructor can stand at the front of a classroom and move sliders below a simulation to control the simulation.</p> <p>For effective use of smart boards, we use a minimum text size of 16 for control labels and values.</p>"},{"location":"glossary/#socratic-method","title":"Socratic Method","text":"<p>The Socratic Method is a form of cooperative argumentative dialogue between individuals, based on asking and answering questions to stimulate critical thinking and to draw out ideas and underlying presuppositions. It is named after the Classical Greek philosopher Socrates and is used to promote a deeper understanding of complex ideas.</p>"},{"location":"glossary/#tokenization","title":"Tokenization","text":"<p>Tokenization is the process of converting text into smaller units, called tokens. In natural language processing, tokens usually represent words, but they can also include punctuation marks, numbers, and other characters. Tokenization is a fundamental step in text processing, allowing models to understand and manipulate text by breaking it down into manageable pieces. It's essential for tasks like sentiment analysis, language translation, and text generation.</p>"},{"location":"glossary/#training-vs-inference","title":"Training vs Inference","text":"<p>In the context of machine learning, 'Training' refers to the process of teaching a model to make predictions or decisions, typically by feeding it a large set of labeled data. 'Inference,' on the other hand, is the stage where the trained model is used to make predictions on new, unseen data. Training is a compute-intensive process that adjusts the model's parameters, while inference involves applying these parameters to make quick decisions or analysis.</p>"},{"location":"glossary/#user-experience","title":"User Experience","text":"<p>User Experience (UX) refers to the overall experience of a person using a product, system, or service, especially in terms of how easy or pleasing it is to use. It encompasses a variety of aspects, including usability, design, ergonomics, functionality, performance, and the user's emotional response. UX is a comprehensive concept that aims to improve customer satisfaction and loyalty through the utility, ease of use, and pleasure provided in the interaction with a product.</p> <p>In an educational setting, UX can be applied to create interactive simulations for classrooms. For instance, a science teacher might use a UX-designed interactive simulation to teach concepts of physics. The simulation, with its intuitive interface, engaging graphics, and responsive feedback, allows students to experiment with different variables in a physics experiment. This direct, hands-on interaction enhances learning by making abstract concepts tangible and easier to understand. The UX design ensures that the simulation is user-friendly, keeping students focused on learning rather than struggling with the technology. By doing so, it not only makes learning more effective but also more enjoyable, increasing student engagement and fostering a deeper understanding of the subject matter.</p>"},{"location":"glossary/#vector-stores","title":"Vector Stores","text":"<p>Vector stores are specialized databases designed to efficiently store and retrieve high-dimensional data, such as vectors produced by machine learning models. They are essential in tasks like similarity search and recommendation systems.</p>"},{"location":"glossary/#visual-studio-code","title":"Visual Studio Code","text":"<p>Visual Studio Code (VS Code) is a free, open-source code editor developed by Microsoft. It's widely used by developers due to its support for a variety of programming languages, built-in Git integration, debugging tools, and a vast ecosystem of extensions. VS Code is known for its lightweight design, cross-platform availability, and powerful code editing and navigation capabilities.</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>LangChain is about how we use generative AI to  harness the power of generative AI and Large-Language Models. The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/learn-langchain\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n langchain python=3\nconda activate langchain\npip install langchain mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this GitHub repository and related course materials (slides, notebooks, quizzes) are governed by the following license.</p> <p></p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"presentations/","title":"Presentations for Intelligent Agents and Python LangChain","text":"<p>TBD</p>"},{"location":"references/","title":"LangChain References","text":"<ol> <li>YouTube Video LangChain in 13 Minutes - 13 minute tutorial</li> <li>LangChain in 13 Minutes GitHub Repo</li> <li>LLM Powered Autonomous Agents by Lilian Weng - a great writeup on how to build autonomous agents.  A nice discussion of how to decompose tasks using LLMs.</li> </ol>"},{"location":"school-agent-process/","title":"Detailed Plan to Leverage Intelligent Agents in K-12 School Systems","text":"<p>After we learn how to use LangChain to build intelligent agents in a school we can then start to apply these skills in a school system.</p> <p>Here are the steps to do this.</p>"},{"location":"school-agent-process/#1-assessment-of-needs-and-challenges","title":"1. Assessment of Needs and Challenges","text":"<ul> <li>School or District Strategy Understand the strategic goals of the school or district.  What is their mission and values? What are the unique needs of their community?  How does their student population vary?</li> <li>Survey Staff: Conduct detailed surveys with teachers and administrators to understand their daily tasks, challenges, and areas where they feel overwhelmed or inefficient.</li> <li>Identify Repetitive Tasks: Pinpoint repetitive and time-consuming tasks like grading, attendance tracking, scheduling, and administrative paperwork.</li> <li>Find Regulatory Documents and Contacts: Find what the regulatory guidelines are for accessing data about teachers and students.  Find the key contacts in legal, security and ethics who will approve any projects that use sensitive data.  Verify that all team members are familiar with the Family Educational Rights and Privacy Act FERPA.</li> </ul>"},{"location":"school-agent-process/#2-introduction-to-generative-ai-and-intelligent-agents","title":"2. Introduction to Generative AI and Intelligent Agents","text":"<ul> <li>Educational Workshops: Organize workshops to educate staff about intelligent agents, their capabilities, potential benefits, and limitations. Include exposure to tools such as ChatGPT and MagicSchool.ai.</li> <li>Focus on Prompt Skills Focus on simple skills such as designing prompts to get a clear understanding of what can and can't be done with generative AI tools.</li> <li>Demystify Technology: Address common misconceptions and fears about AI, focusing on how it assists rather than replaces human roles.</li> </ul>"},{"location":"school-agent-process/#3-selection-of-suitable-intelligent-agent-tools","title":"3. Selection of Suitable Intelligent Agent Tools","text":"<ul> <li>Research and Select Tools: Based on the needs assessment, select intelligent agent tools tailored to the school environment. Consider tools for:</li> <li>Automated grading and feedback for assignments.</li> <li>Attendance and behavior tracking.</li> <li>Scheduling and calendar management.</li> <li>Streamlining communication between parents, teachers, and students.</li> <li>Generation of lesson plans customized to different groups</li> <li>Generation of interactive teaching tools such as Micro Simulators that can be   customized by generative AI</li> <li>Alignment of Tools with School Policy: Review the school policy to make sure that tools are used in accordance with the school, district, state and national policy guidelines.</li> </ul>"},{"location":"school-agent-process/#4-customization-and-integration-projects","title":"4. Customization and Integration Projects","text":"<ul> <li>Collaborate with Developers: Work with AI developers, teachers and students to customize tools for specific school needs, integrating with existing school management systems.</li> <li>Data Privacy and Security: Ensure all projects comply with privacy laws protecting student data.</li> </ul>"},{"location":"school-agent-process/#5-pilot-programs","title":"5. Pilot Programs","text":"<ul> <li>Implement Pilot Programs: Start with pilot programs in select classrooms or administrative departments.  Look for teachers who are visionary thought leaders that can help others understand both the pros and cons of AI in the classroom.</li> <li>Collect Feedback: Regularly collect feedback from users to understand the effectiveness and any issues.</li> </ul>"},{"location":"school-agent-process/#6-training-and-support","title":"6. Training and Support","text":"<ul> <li>Comprehensive Training: Provide in-depth training for teachers and administrators on how to use these tools effectively.</li> <li>Ongoing Support: Establish a support system for troubleshooting and assistance.</li> </ul>"},{"location":"school-agent-process/#7-evaluation-and-scaling","title":"7. Evaluation and Scaling","text":"<ul> <li>Evaluate Impact: Assess the impact on efficiency, workload, and overall school functioning.</li> <li>Iterative Improvement: Continuously improve the tools based on feedback and performance data.</li> <li>Scale Gradually: If successful, gradually scale the use of intelligent agents across the school district.</li> </ul>"},{"location":"school-agent-process/#8-continuous-learning-and-adaptation","title":"8. Continuous Learning and Adaptation","text":"<ul> <li>Stay Updated: Keep abreast of advancements in AI and intelligent agent technologies.</li> <li>Adapt and Evolve: Regularly update and adapt the tools to meet changing needs and leverage new capabilities.</li> </ul>"},{"location":"school-agent-process/#9-fostering-a-collaborative-environment","title":"9. Fostering a Collaborative Environment","text":"<ul> <li>Encourage Collaboration: Foster a culture where teachers and administrators can share best practices and tips for using these tools.</li> <li>Feedback Loops: Create channels for ongoing feedback to developers and IT staff for continuous improvement.</li> </ul>"},{"location":"school-agent-process/#10-ensuring-ethical-and-responsible-use","title":"10. Ensuring Ethical and Responsible Use","text":"<ul> <li>Ethical Guidelines: Develop clear guidelines for ethical use of AI in schools, ensuring it supports educational goals without bias or detriment to students.</li> <li>Regular Audits: Conduct regular audits to ensure the intelligent agents are being used responsibly and effectively.</li> </ul>"},{"location":"school-agent-process/#conclusion","title":"Conclusion","text":"<p>The integration of intelligent agents in K-12 schools should be a carefully planned and iterative process, always prioritizing the needs and well-being of students, teachers, and administrators. By strategically implementing these technologies, schools can enhance efficiency and effectiveness, allowing educators to focus more on teaching and less on administrative tasks.</p>"},{"location":"u-of-mn-eecs-course/","title":"Course Proposal","text":"<p>Title: Building Intelligent Agents with Generative AI and LangCHain</p> <p>We have been asked to lead a team of students from the University of Minnesota EECS department in a senior seminar on the use of generative AI to solve specific problems.  Our focus will be on prompt engineering, LangChian, chatbots, and the design of intelligent agents.</p> <p>Students have the flexibility to pick problems that are relevant to their interests, but the generation of content for software and lesson plan generation is strongly encouraged.  Specifically, we will be demonstrating the use of ChatGPT to create MicroSimulations for use in the classroom.</p>"},{"location":"u-of-mn-eecs-course/#student-prerequisites","title":"Student Prerequisites","text":"<ol> <li>Intermediate Python coding skills</li> <li>Basic knowledge of GitHub</li> <li>Knowledge of how to run UNIX Shell commands from a terminal</li> <li>Approximately 60 hours of time</li> <li>Each student should have access to the OpenAI ChatBot Pro tools ($20/month)</li> </ol>"},{"location":"u-of-mn-eecs-course/#process","title":"Process","text":"<ol> <li> <p>We will have an initial lecture that will focus on generative AI and the use of ChatGPT</p> </li> <li> <p>Students who choose to participate will be assigned to teams of five people. </p> </li> <li> <p>Each team will be asked to create a document that clearly outlines the goals of their project, such as developing a website that utilizes generative AI (like ChatGPT) to personalize educational content. Ensure these objectives align with the curriculum and learning outcomes.  The focus of this document is what the program should do without regard to how it will do it.</p> </li> <li> <p>Teams will draft a six-week plan where students each person spends 10-hours per week.  The plan will break the project into smaller, manageable milestones. This could include initial research, design phase, coding, testing, and final presentation.</p> </li> <li> <p>Each team will be responsible for creating a website using GitHub pages and mkdocs.  A significant portion of the assessment will be made on the quality of this website.</p> </li> </ol>"},{"location":"u-of-mn-eecs-course/#responsibility-of-dan-mccreary","title":"Responsibility of Dan McCreary","text":"<ol> <li>Provide overall outlines of the course content and goals</li> <li>Assist students in getting their Python development environment working (excluding PC administration)</li> <li>Deliver key lectures and maintain content to the online Python and LangChain tools</li> <li>Assist students in getting their Markdown content on their GitHub Pages</li> <li>Assisting in assessment when appropriate</li> </ol>"},{"location":"u-of-mn-eecs-course/#learning-objectives","title":"Learning Objectives","text":"<p>At the end of this course, students will:</p> <ol> <li>understand the capabilities of deep neural networks to generate content</li> <li>be familiar with the skills involved in prompt engineering</li> <li>know the steps to create a website with GitHub Pages</li> <li>know how Markdown language is used to hold content</li> <li>understand the role of generative AI in creating chatbots and agents</li> <li>be aware of and have an appreciation of the rate of change of tools such as LangChain</li> <li>appreciate the role of the open-source community in the creation of new AI tools</li> </ol>"},{"location":"u-of-mn-eecs-course/#assessment","title":"Assessment","text":"<ol> <li>50% is how your fellow students rate your participation</li> <li>20% is the quality of the final product</li> <li>20% is the quality of the code and documentation</li> <li>10% can parts of the system be leveraged by future students (reusable components)</li> </ol>"},{"location":"lessons/","title":"Lessons","text":""},{"location":"lessons/01-hello-world/","title":"Hello World","text":"<p>In this lab, we run the simplest code possible to test using the OpenAI API using a low-cost small model.</p> <p>This program should also test that the OPENAI_API_KEY is correctly stored in .env file that is NEVER checked into GitHub by correctly adding it to the .gitignore file.  Check this now by running the following commmand:</p> <pre><code>cat .gitignore\n</code></pre> <p>You should see somthing like:</p> <pre><code>site\n.vscode\n.DS_Store\n.cache\n~$*\n.env\n</code></pre> <p>To keep our testing costs low, we will use the GPT 3.5 Turbo Model</p> <pre><code>OPENAI_MODEL='gpt-3.5-turbo'\n</code></pre>"},{"location":"lessons/01-hello-world/#sample-program","title":"Sample Program","text":"<pre><code>import os\nfrom openai import OpenAI\n\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\ncompletion = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  max_tokens=1,\n  messages=[\n    {\"role\": \"user\", \"content\": \"What is the opposite of up?  Answer in a single word.\"}\n  ]\n)\n\nprint(completion.choices[0].message)\n</code></pre>"},{"location":"lessons/03-openai-rate-limits/","title":"OpenAI Rate Limits","text":"<p>If you get the OpenAI 429 error:</p> <pre><code>raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n</code></pre> <p>You can see what Tier you are on here:</p> <p>Account Tier Limits</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"lessons/05-generate-dialogs/","title":"Generating Dialogs with OpenAI's API","text":"<p>In this example, we want to generate sample dialogs between a teacher and a student on various robotics topics for a  school's Robot Day event.  These dialogs will help teachers change their presentation based on the grade-level of the student.</p> <p>Here are the sample topics:</p> <ol> <li>Batteries</li> <li>Motors</li> <li>Sensors</li> <li>Displays</li> <li>Microcontrollers</li> </ol> <p>The grade levels are grades 1 to 5.</p> <p>For each topic, we want to generate a single-paragraph discussion between a teacher and the student on how this topic is part of robotics.</p> <pre><code>import os\nfrom openai import OpenAI\n\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\ncompletion = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  max_tokens=1,\n  messages=[\n    {\"role\": \"user\", \"content\": \"What is the opposite of up?  Answer in a single word.\"}\n  ]\n)\n\nprint(completion.choices[0].message)\n</code></pre>"},{"location":"lessons/langchain-in-13-minutes/","title":"LangChain in 13 Minutes","text":"<pre><code>python-dotenv==1.0.0\nlangchain==0.0.137\npinecone-client==2.2.1\n</code></pre> <p>Here are some samples of using the LangChain APIs.</p>"},{"location":"lessons/langchain-in-13-minutes/#load-environment-variables","title":"Load Environment Variables","text":"<pre><code># Load environment variables\n\nfrom dotenv import load_dotenv,find_dotenv\nload_dotenv(find_dotenv())\n</code></pre>"},{"location":"lessons/langchain-in-13-minutes/#run-basic-query","title":"Run Basic Query","text":"<pre><code># Run basic query with OpenAI wrapper\n\nfrom langchain.llms import OpenAI\nllm = OpenAI(model_name=\"text-davinci-003\")\nllm(\"explain large language models in one sentence\")\n</code></pre>"},{"location":"lessons/langchain-in-13-minutes/#run-langchain-imports","title":"Run LangChain Imports","text":"<pre><code># import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n\nfrom langchain.schema import (\n    AIMessage,\n    HumanMessage,\n    SystemMessage\n)\nfrom langchain.chat_models import ChatOpenAI\n</code></pre>"},{"location":"lessons/langchain-in-13-minutes/#have-gpt-generate-python-code","title":"Have GPT generate Python Code","text":"<p>In this example, we combine the System Message with the Human Message. The API will concatenate them together and send it to OpenAI.</p> <pre><code>chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\nmessages = [\n    SystemMessage(content=\"You are an expert data scientist\"),\n    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n]\nresponse=chat(messages)\n\nprint(response.content,end='\\n')\n</code></pre> <p></p>"},{"location":"lessons/langchain-in-13-minutes/#import-prompts","title":"Import Prompts","text":""},{"location":"lessons/langchain-in-13-minutes/#run-with-prompt-template","title":"Run With Prompt Template","text":""},{"location":"lessons/langchain-in-13-minutes/#use-langchain-to-build-a-prompt-only-response-pipeline","title":"Use LangChain to Build a Prompt Only Response Pipeline","text":"<pre><code># Import LLMChain and define chain with language model and prompt as arguments.\n\nfrom langchain.chains import LLMChain\nchain = LLMChain(llm=llm, prompt=prompt)\n\n# Run the chain only specifying the input variable.\nprint(chain.run(\"autoencoder\"))\n</code></pre>"},{"location":"lessons/langchain-in-13-minutes/#sequential-chain","title":"Sequential Chain","text":"<p>Here we put two components together to form a chain.  The output of <code>chain</code> is fed into <code>chain_two</code></p> <pre><code># Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n\nfrom langchain.chains import SimpleSequentialChain\noverall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n\n# Run the chain specifying only the input variable for the first chain.\nexplanation = overall_chain.run(\"autoencoder\")\nprint(explanation)\n</code></pre>"},{"location":"setup/","title":"Getting Started with Building Intelligent Agents for Education","text":"<p>This course depends on the following:</p> <ol> <li>Each user has an OpenAI account</li> <li>Each user has a Pinecone account</li> <li>Users have a computer with at least 8GB RAM</li> <li>Users have Visual Studio Code installed</li> </ol>"},{"location":"setup/#openai-setup","title":"OpenAI Setup","text":"<p>[]</p>"},{"location":"setup/env-test/","title":"Testing Your Environment Variables","text":""},{"location":"setup/env-test/#checking-the-openai-api-key-is-set","title":"Checking the OpenAI API Key is Set","text":"<pre><code>import os\nfrom dotenv import load_dotenv, find_dotenv\n\n# Load the environment file\nload_dotenv(find_dotenv())\n\n# Function to check if OPENAI_API_KEY is set\ndef check_openai_api_key():\n    # Check if the OPENAI_API_KEY environment variable is set\n    api_key = os.getenv(\"OPENAI_API_KEY\")\n    if api_key:\n        return \"OPENAI_API_KEY is set.\"\n    else:\n        return \"OPENAI_API_KEY is not set.\"\n\n# Call the function and print the result\nresult = check_openai_api_key()\nprint(result)\n</code></pre>"},{"location":"setup/env-test/#checking-mandatory-environment-variables","title":"Checking Mandatory Environment Variables","text":"<pre><code>OPENAI_API_KEY=\"...\"\nPINECONE_API_KEY=\"...\"\nPINECONE_ENV=\"...\"\n</code></pre> <pre><code>import os\nfrom dotenv import load_dotenv, find_dotenv\n\n# Load the environment file\nload_dotenv(find_dotenv())\n\n# Function to check if specific environment variables are set\ndef check_environment_variables():\n    results = {}\n\n    # List of environment variables to check\n    env_vars = [\"OPENAI_API_KEY\", \"PINECONE_API_KEY\", \"PINECONE_ENV\"]\n\n    # Check each environment variable\n    for var in env_vars:\n        results[var] = \"set\" if os.getenv(var) else \"not set\"\n\n    return results\n\n# Call the function and print the results\nenv_var_results = check_environment_variables()\nprint(env_var_results)\n</code></pre>"},{"location":"setup/jupyter-notebook/","title":"Jupyter Notebook","text":"<p>You will need to make sure you can run Jupyter Notebooks.</p> <p>You can load the Jupyter Notebook Extensions</p> <p></p>"},{"location":"setup/openai/","title":"OpenAI","text":"<p>Each student will need their own OpenAI ChatGPT Pro account.</p>"},{"location":"setup/pinecone/","title":"Pinecone","text":"<p>Free Tier:</p> <p>Limited to one index and one project. Community Support Only</p>"},{"location":"setup/pinecone/#environment-settings","title":"Environment Settings","text":"<p>Make sure to put .env in your .gitignore file to make sure that you don't put this fine on GitHub</p> <pre><code>PINECONE_ENV=\"...\"\nPINECONE_API_KEY=\"...\"\n</code></pre> <p>The free version uses the Google Cloud Platform:</p> <pre><code>OPENAI_API_KEY=\"...\"\nPINECONE_API_KEY=\"...\"\nPINECONE_ENV=\"gcp-starter\"\n</code></pre>"},{"location":"setup/pinecone/#pinecone-project","title":"Pinecone Project","text":""},{"location":"setup/pinecone/#pinecone-ai-agent-api-key","title":"Pinecone AI Agent API Key","text":""},{"location":"setup/vscode/","title":"Setting up Visual Studio Code","text":""},{"location":"setup/vscode/#intall-the-jupyter-notebook-extension","title":"Intall the Jupyter Notebook Extension","text":"<p>Code -&gt; Settings -&gt; Extensions -&gt;</p> <p></p>"},{"location":"setup/vscode/#configure-to-use-the-langchain-conda-env","title":"Configure to use the LangChain Conda Env","text":""}]}